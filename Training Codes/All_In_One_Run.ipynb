{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# CELL 1: INSTALL LIBRARIES\n",
        "# ==========================================\n",
        "print(\"â³ Installing libraries... (This takes about 1 min)\")\n",
        "\n",
        "# Install Dependencies\n",
        "!pip install flask pyngrok transformers sentence-transformers textstat textblob vadersentiment nrclex scikit-learn tensorflow-text python-dotenv huggingface_hub joblib networkx\n",
        "\n",
        "# Download NLTK Data\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "print(\"âœ… Installation Complete!\")"
      ],
      "metadata": {
        "id": "ouz5S53KdXub",
        "outputId": "69e2e2db-bff3-4e9d-c686-084b9f8d6f3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â³ Installing libraries... (This takes about 1 min)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.5.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Collecting textstat\n",
            "  Downloading textstat-0.7.12-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.12/dist-packages (0.19.0)\n",
            "Collecting vadersentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
            "Collecting nrclex\n",
            "  Downloading NRCLex-4.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.36.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (3.6.1)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.3.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.4)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cu126)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Collecting pyphen (from textstat)\n",
            "  Downloading pyphen-0.17.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from textstat) (3.9.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from textstat) (75.2.0)\n",
            "INFO: pip is looking at multiple versions of nrclex to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting nrclex\n",
            "  Downloading NRCLex-3.0.0.tar.gz (396 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m396.4/396.4 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: tensorflow<2.20,>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-text) (2.19.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (5.29.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (3.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (0.5.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (0.18.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (0.7.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (0.1.2)\n",
            "Downloading pyngrok-7.5.0-py3-none-any.whl (24 kB)\n",
            "Downloading textstat-0.7.12-py3-none-any.whl (176 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m176.6/176.6 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyphen-0.17.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: nrclex\n",
            "  Building wheel for nrclex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nrclex: filename=NRCLex-3.0.0-py3-none-any.whl size=43309 sha256=50dea1019ec5239eba63a2b5d5f52804b9343a1b4e06311287e671c95a5577c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/e8/d0/e3c3da0ef3b37ef4381dbf5c9401f3a9861a63ce221b13d8bb\n",
            "Successfully built nrclex\n",
            "Installing collected packages: pyphen, pyngrok, vadersentiment, textstat, nrclex\n",
            "Successfully installed nrclex-3.0.0 pyngrok-7.5.0 pyphen-0.17.2 textstat-0.7.12 vadersentiment-3.3.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Installation Complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# CELL 2: NGROK AUTHENTICATION\n",
        "# ==========================================\n",
        "from pyngrok import ngrok\n",
        "import getpass\n",
        "\n",
        "print(\"1. Go to this link to get your token: https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
        "print(\"2. Copy the token and paste it below.\")\n",
        "\n",
        "NGROK_TOKEN = getpass.getpass(\"Enter Ngrok Token: \")\n",
        "\n",
        "if NGROK_TOKEN.strip():\n",
        "    ngrok.set_auth_token(NGROK_TOKEN)\n",
        "    print(\"âœ… Ngrok Authenticated Successfully!\")\n",
        "else:\n",
        "    print(\"âŒ No token provided. The app might fail to create a public link.\")"
      ],
      "metadata": {
        "id": "kkXu-mKfdYVt",
        "outputId": "4b8fc8ae-7016-40ee-94e2-26e09160e0e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Go to this link to get your token: https://dashboard.ngrok.com/get-started/your-authtoken\n",
            "2. Copy the token and paste it below.\n",
            "Enter Ngrok Token: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "âœ… Ngrok Authenticated Successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# CELL 3: START SERVER\n",
        "# ==========================================\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# 1. Move index.html to 'templates' folder\n",
        "if not os.path.exists(\"templates\"):\n",
        "    os.makedirs(\"templates\")\n",
        "\n",
        "if os.path.exists(\"index.html\"):\n",
        "    shutil.move(\"index.html\", \"templates/index.html\")\n",
        "    print(\"ğŸ“‚ 'index.html' moved to templates folder.\")\n",
        "\n",
        "# 2. Run the App\n",
        "if not os.path.exists(\"app.py\"):\n",
        "    print(\"âŒ Error: Please upload 'app.py' to the Files folder on the left!\")\n",
        "else:\n",
        "    print(\"ğŸš€ Starting Flask App...\")\n",
        "    print(\"ğŸ”— Look for the public URL below (e.g., http://xxxx.ngrok-free.app)\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    !python app.py"
      ],
      "metadata": {
        "id": "gNNbz_VCdtBj",
        "outputId": "52494152-be71-468c-cda3-a62d72097248",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Starting Flask App...\n",
            "ğŸ”— Look for the public URL below (e.g., http://xxxx.ngrok-free.app)\n",
            "==================================================\n",
            "ğŸš€ Using Device: cuda\n",
            "2026-01-01 19:04:07.337009: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1767294247.357872    2144 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767294247.364169    2144 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1767294247.379528    2144 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767294247.379568    2144 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767294247.379572    2144 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767294247.379577    2144 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-01 19:04:07.384334: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 331kB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 1.44MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 2.88MB/s]\n",
            "config.json: 100% 570/570 [00:00<00:00, 5.25MB/s]\n",
            "â³ Loading Hybrid-8 model...\n",
            "model.safetensors: 100% 440M/440M [00:04<00:00, 101MB/s] \n",
            "hybrid_fake_news_model.pth: 100% 438M/438M [00:06<00:00, 63.2MB/s]\n",
            "scaler.pkl: 100% 807/807 [00:00<00:00, 1.65kB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.8.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "âœ… Hybrid-8 loaded\n",
            "â³ Loading Sklearn model...\n",
            "bert_sklearn.pkl: 100% 7.01k/7.01k [00:00<00:00, 14.4kB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.8.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "âœ… Sklearn model loaded\n",
            "â³ Loading Dense TF model...\n",
            "bert.pkl: 100% 118k/118k [00:00<00:00, 171kB/s]\n",
            "2026-01-01 19:04:35.464842: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1767294275.466347    2144 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13020 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "âœ… Dense TF model loaded\n",
            "â³ Loading Hybrid-25 model...\n",
            "tokenizer_config.json: 100% 1.27k/1.27k [00:00<00:00, 9.21MB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 2.83MB/s]\n",
            "special_tokens_map.json: 100% 125/125 [00:00<00:00, 847kB/s]\n",
            "model_config.pt: 100% 1.48k/1.48k [00:00<00:00, 2.35kB/s]\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "pytorch_model.bin: 100% 439M/439M [00:04<00:00, 105MB/s]\n",
            "feature_scaler.pkl: 100% 1.89k/1.89k [00:00<00:00, 8.26kB/s]\n",
            "pre_extractor.pkl: 100% 843k/843k [00:00<00:00, 874kB/s]\n",
            "post_extractor.pkl: 100% 843k/843k [00:02<00:00, 409kB/s]  \n",
            "preprocessor.pkl: 100% 1.57k/1.57k [00:00<00:00, 6.69kB/s]\n",
            "âœ… Hybrid-25 loaded\n",
            "â³ Loading Summarization Models...\n",
            "modules.json: 100% 349/349 [00:00<00:00, 2.79MB/s]\n",
            "config_sentence_transformers.json: 100% 283/283 [00:00<00:00, 1.96MB/s]\n",
            "README.md: 100% 19.3k/19.3k [00:00<00:00, 73.1MB/s]\n",
            "sentence_bert_config.json: 100% 57.0/57.0 [00:00<00:00, 493kB/s]\n",
            "config.json: 100% 545/545 [00:00<00:00, 3.65MB/s]\n",
            "model.safetensors: 100% 438M/438M [00:10<00:00, 43.6MB/s]\n",
            "tokenizer_config.json: 100% 1.61k/1.61k [00:00<00:00, 11.8MB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 1.53MB/s]\n",
            "tokenizer.json: 100% 711k/711k [00:00<00:00, 1.54MB/s]\n",
            "special_tokens_map.json: 100% 964/964 [00:00<00:00, 7.26MB/s]\n",
            "config.json: 100% 312/312 [00:00<00:00, 1.89MB/s]\n",
            "âœ… SBERT V2 (MPNet) loaded\n",
            "modules.json: 100% 349/349 [00:00<00:00, 2.97MB/s]\n",
            "config_sentence_transformers.json: 100% 116/116 [00:00<00:00, 894kB/s]\n",
            "README.md: 10.5kB [00:00, 14.8MB/s]\n",
            "sentence_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 456kB/s]\n",
            "config.json: 100% 612/612 [00:00<00:00, 1.59MB/s]\n",
            "model.safetensors: 100% 90.9M/90.9M [00:01<00:00, 70.0MB/s]\n",
            "tokenizer_config.json: 100% 350/350 [00:00<00:00, 2.93MB/s]\n",
            "vocab.txt: 232kB [00:00, 123MB/s]\n",
            "tokenizer.json: 466kB [00:00, 59.5MB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 750kB/s]\n",
            "config.json: 100% 190/190 [00:00<00:00, 1.65MB/s]\n",
            "âœ… SBERT Base (MiniLM) loaded\n",
            "\n",
            "==================================================================\n",
            " ğŸš€ PUBLIC URL: https://chordamesodermal-commentatorial-nicolette.ngrok-free.dev\n",
            "==================================================================\n",
            "\n",
            " * Serving Flask app 'app'\n",
            " * Debug mode: off\n",
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [01/Jan/2026 19:05:18] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [01/Jan/2026 19:05:19] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "\n",
            "ğŸ” DEBUG: Received request. Model: hybrid25, Summarizer: sbert_v2\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "INFO:werkzeug:127.0.0.1 - - [01/Jan/2026 19:05:42] \"POST /analyze HTTP/1.1\" 200 -\n",
            "\n",
            "ğŸ” DEBUG: Received request. Model: hybrid25, Summarizer: sbert_base\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "INFO:werkzeug:127.0.0.1 - - [01/Jan/2026 19:05:52] \"POST /analyze HTTP/1.1\" 200 -\n",
            "\n",
            "ğŸ” DEBUG: Received request. Model: dense, Summarizer: sbert_base\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1767294359.158783    2412 service.cc:152] XLA service 0x7f8e3c019130 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1767294359.158822    2412 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2026-01-01 19:05:59.198208: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1767294359.275734    2412 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "I0000 00:00:1767294359.628045    2412 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606ms/step\n",
            "INFO:werkzeug:127.0.0.1 - - [01/Jan/2026 19:05:59] \"POST /analyze HTTP/1.1\" 200 -\n",
            "Exception ignored in: <module 'threading' from '/usr/lib/python3.12/threading.py'>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1575, in _shutdown\n",
            "    def _shutdown():\n",
            "    \n",
            "KeyboardInterrupt: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hygXAEqijfFH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}